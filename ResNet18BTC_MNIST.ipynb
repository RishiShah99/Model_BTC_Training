{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T14:44:53.799536Z","iopub.execute_input":"2025-07-10T14:44:53.800167Z","iopub.status.idle":"2025-07-10T14:44:54.093750Z","shell.execute_reply.started":"2025-07-10T14:44:53.800117Z","shell.execute_reply":"2025-07-10T14:44:54.093178Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom PIL import Image, ImageFilter\nfrom tqdm import tqdm\nimport os\n\n# --- Device Setup ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- Hyperparameters ---\nlearning_rate = 0.01\nmomentum = 0.9\nweight_decay = 1e-4\nbatch_size = 128\nnum_epochs_total = 50\nepochs_per_blur = 10\nblur_levels = [8, 4, 2, 1, 0]\n\n# --- Gaussian Blur Wrapper ---\nclass GaussianBlur:\n    def __init__(self, sigma):\n        self.sigma = sigma\n\n    def __call__(self, img):\n        return img.filter(ImageFilter.GaussianBlur(self.sigma))\n\n# --- DataLoader Generator ---\ndef get_dataloader(blur_level, batch_size):\n    transform = transforms.Compose([\n        transforms.Grayscale(num_output_channels=3),\n        transforms.CenterCrop((256, 256)),\n        transforms.Resize((224, 224)),\n        transforms.Lambda(lambda img: GaussianBlur(blur_level)(img)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# --- Test Loader (no blur) ---\ntest_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.CenterCrop((256, 256)),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# --- Compute Validation Accuracy with BN-safe Evaluation ---\ndef evaluate_accuracy(model, val_loader, device):\n    model.train()  # Avoid BatchNorm instability\n    correct = 0\n    total = 0\n    val_pbar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n    with torch.no_grad():\n        for inputs, labels in val_pbar:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            if torch.isnan(outputs).any():\n                print(\"âš ï¸ NaNs detected, skipping batch.\")\n                continue\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            acc = 100 * correct / total if total > 0 else 0\n            val_pbar.set_postfix(acc=f\"{acc:.2f}%\")\n    return 100 * correct / total if total > 0 else 0\n\n# --- Training Loop with single rolling checkpoint ---\ndef train_model(model, criterion, optimizer, train_loader, val_loader, device,\n                num_epochs=10, blur_level=0, current_epoch_offset=0):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Blur {blur_level})\", leave=False)\n        for inputs, labels in pbar:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n        acc = evaluate_accuracy(model, val_loader, device)\n        print(f\"âœ… Epoch {current_epoch_offset + epoch + 1} done | Loss: {running_loss:.4f} | Accuracy: {acc:.2f}%\")\n\n        # Overwrite the same checkpoint file\n        checkpoint = {\n            'epoch': current_epoch_offset + epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'blur_level': blur_level\n        }\n        torch.save(checkpoint, \"btc_checkpoint.pth\")\n        print(f\"ðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch {current_epoch_offset + epoch + 1})\")\n\n    return model\n\n# --- BTC Trainer with resume ---\ndef adjust_blur_and_train(model):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n                          momentum=momentum, weight_decay=weight_decay)\n\n    # Resume if btc_checkpoint.pth exists\n    start_epoch = 0\n    start_blur = 0\n\n    if os.path.exists(\"btc_checkpoint.pth\"):\n        print(f\"ðŸ”„ Found checkpoint: btc_checkpoint.pth\")\n        checkpoint = torch.load(\"btc_checkpoint.pth\")\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_epoch = checkpoint['epoch']\n        start_blur = checkpoint['blur_level']\n        print(f\"Resuming from blur {start_blur}, epoch {start_epoch}\")\n\n    current_epoch = start_epoch\n    blur_index = blur_levels.index(start_blur) if start_epoch > 0 else 0\n\n    for blur in blur_levels[blur_index:]:\n        if current_epoch >= num_epochs_total:\n            break\n        print(f\"\\n--- Training with blur level {blur} ---\")\n        epochs_to_train = min(epochs_per_blur, num_epochs_total - current_epoch)\n        train_loader = get_dataloader(blur, batch_size)\n        model = train_model(model, criterion, optimizer, train_loader, test_loader, device,\n                            num_epochs=epochs_to_train, blur_level=blur, current_epoch_offset=current_epoch)\n        current_epoch += epochs_to_train\n\n    return model\n\n# --- Main ---\nif __name__ == '__main__':\n    resnet = models.resnet18(pretrained=False)\n    resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n    resnet = resnet.to(device)\n\n    print(\"ðŸš€ Starting BTC Training for ResNet-18...\")\n    trained_model = adjust_blur_and_train(resnet)\n\n    torch.save(trained_model.state_dict(), \"resnet18_btc_mnist_final.pth\")\n    print(\"âœ… Final model saved: resnet18_btc_mnist_final.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T14:44:54.111786Z","iopub.execute_input":"2025-07-10T14:44:54.112301Z","iopub.status.idle":"2025-07-10T21:11:31.688199Z","shell.execute_reply.started":"2025-07-10T14:44:54.112280Z","shell.execute_reply":"2025-07-10T21:11:31.687406Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 35.2MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.04MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 9.21MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 7.80MB/s]\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"ðŸš€ Starting BTC Training for ResNet-18...\n\n--- Training with blur level 8 ---\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 1 done | Loss: 513.0292 | Accuracy: 14.77%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 1)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 2 done | Loss: 245.0312 | Accuracy: 7.88%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 2)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 3 done | Loss: 183.5884 | Accuracy: 8.06%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 3)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 4 done | Loss: 151.5682 | Accuracy: 8.44%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 4)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 5 done | Loss: 133.2015 | Accuracy: 10.24%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 5)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 6 done | Loss: 122.4183 | Accuracy: 9.31%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 6)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 7 done | Loss: 111.1967 | Accuracy: 9.47%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 7)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 8 done | Loss: 102.2539 | Accuracy: 10.03%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 8)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 9 done | Loss: 98.2429 | Accuracy: 9.83%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 9)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 10 done | Loss: 90.9857 | Accuracy: 9.53%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 10)\n\n--- Training with blur level 4 ---\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 11 done | Loss: 160.1027 | Accuracy: 59.62%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 11)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 12 done | Loss: 72.6438 | Accuracy: 55.47%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 12)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 13 done | Loss: 54.1382 | Accuracy: 54.49%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 13)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 14 done | Loss: 45.2932 | Accuracy: 54.54%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 14)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 15 done | Loss: 39.5331 | Accuracy: 56.64%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 15)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 16 done | Loss: 34.2580 | Accuracy: 56.88%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 16)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 17 done | Loss: 31.7464 | Accuracy: 58.74%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 17)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 18 done | Loss: 28.4596 | Accuracy: 58.50%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 18)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 19 done | Loss: 24.2696 | Accuracy: 59.01%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 19)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 20 done | Loss: 22.7817 | Accuracy: 59.40%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 20)\n\n--- Training with blur level 2 ---\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 21 done | Loss: 40.6033 | Accuracy: 93.13%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 21)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 22 done | Loss: 19.0708 | Accuracy: 92.73%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 22)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 23 done | Loss: 15.0785 | Accuracy: 92.70%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 23)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 24 done | Loss: 12.2748 | Accuracy: 92.50%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 24)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 25 done | Loss: 9.6729 | Accuracy: 93.00%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 25)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 26 done | Loss: 8.7599 | Accuracy: 92.50%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 26)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 27 done | Loss: 7.0702 | Accuracy: 91.51%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 27)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 28 done | Loss: 6.0791 | Accuracy: 92.35%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 28)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 29 done | Loss: 4.6430 | Accuracy: 92.03%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 29)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 30 done | Loss: 4.7250 | Accuracy: 91.99%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 30)\n\n--- Training with blur level 1 ---\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 31 done | Loss: 14.6885 | Accuracy: 97.60%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 31)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 32 done | Loss: 6.0830 | Accuracy: 97.74%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 32)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 33 done | Loss: 4.1256 | Accuracy: 97.57%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 33)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 34 done | Loss: 2.5385 | Accuracy: 98.38%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 34)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 35 done | Loss: 2.6151 | Accuracy: 98.05%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 35)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 36 done | Loss: 1.6030 | Accuracy: 98.11%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 36)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 37 done | Loss: 1.7847 | Accuracy: 98.23%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 37)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 38 done | Loss: 1.0738 | Accuracy: 98.35%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 38)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 39 done | Loss: 0.4408 | Accuracy: 98.18%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 39)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 40 done | Loss: 0.3065 | Accuracy: 98.32%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 40)\n\n--- Training with blur level 0 ---\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 41 done | Loss: 7.7662 | Accuracy: 98.73%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 41)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 42 done | Loss: 3.2238 | Accuracy: 98.89%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 42)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 43 done | Loss: 1.9509 | Accuracy: 98.86%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 43)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 44 done | Loss: 0.8664 | Accuracy: 98.96%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 44)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 45 done | Loss: 0.7454 | Accuracy: 98.93%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 45)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 46 done | Loss: 0.4349 | Accuracy: 98.94%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 46)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 47 done | Loss: 0.1952 | Accuracy: 98.92%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 47)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 48 done | Loss: 0.1370 | Accuracy: 98.97%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 48)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 49 done | Loss: 0.1250 | Accuracy: 99.00%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 49)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 50 done | Loss: 0.1156 | Accuracy: 98.96%\nðŸ’¾ Checkpoint saved: btc_checkpoint.pth (epoch 50)\nâœ… Final model saved: resnet18_btc_mnist_final.pth\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torchattacks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T21:14:56.180729Z","iopub.execute_input":"2025-07-10T21:14:56.181523Z","iopub.status.idle":"2025-07-10T21:16:27.403546Z","shell.execute_reply.started":"2025-07-10T21:14:56.181499Z","shell.execute_reply":"2025-07-10T21:16:27.402483Z"}},"outputs":[{"name":"stdout","text":"Collecting torchattacks\n  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\nRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (0.21.0+cu124)\nRequirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.15.2)\nRequirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (4.67.1)\nCollecting requests~=2.25.1 (from torchattacks)\n  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.4->torchattacks) (2.4.1)\nCollecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.1->torchattacks)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->torchattacks) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.8.2->torchattacks) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.4->torchattacks) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.4->torchattacks) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.4->torchattacks) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.4->torchattacks) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.4->torchattacks) (2024.2.0)\nDownloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: urllib3, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, idna, chardet, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchattacks\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.4.0\n    Uninstalling urllib3-2.4.0:\n      Successfully uninstalled urllib3-2.4.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: chardet\n    Found existing installation: chardet 5.2.0\n    Uninstalling chardet-5.2.0:\n      Successfully uninstalled chardet-5.2.0\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Uninstalling requests-2.32.3:\n      Successfully uninstalled requests-2.32.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ndatasets 3.6.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\njupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\ntiktoken 0.9.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ndocker 7.1.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\nbigframes 1.42.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\nyfinance 0.2.55 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nsphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\ngoogle-genai 1.9.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntweepy 4.15.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ---------------- Load BTC-trained ResNet-18 ----------------\nfrom torchvision import models\nimport torch.nn as nn\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet18(pretrained=False)\nmodel.fc = nn.Linear(model.fc.in_features, 10)  # MNIST 10 classes\nmodel.load_state_dict(torch.load(\"resnet18_btc_mnist_final.pth\"))\nmodel = model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T21:19:28.541254Z","iopub.execute_input":"2025-07-10T21:19:28.542012Z","iopub.status.idle":"2025-07-10T21:19:28.871362Z","shell.execute_reply.started":"2025-07-10T21:19:28.541975Z","shell.execute_reply":"2025-07-10T21:19:28.870385Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\n\n# ---------------- PGD Attack Setup ----------------\npgd_eps = 0.01         # Changeable\npgd_alpha = 2/255\npgd_steps = 40\n\npgd_attack = torchattacks.PGD(model, eps=pgd_eps, alpha=pgd_alpha, steps=pgd_steps)\n\n# ---------------- PGD Adversarial Accuracy Function ----------------\ndef adversarial_test_pgd(attack, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    for inputs, labels in tqdm(loader, desc=f\"Adversarial Test (PGD)\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n    \n    acc = correct / total\n    print(f\"ðŸ“Š PGD Accuracy (Îµ={pgd_eps}): {acc:.4f}\")\n    return acc\n\n# ---------------- Run PGD Evaluation ----------------\npgd_acc = adversarial_test_pgd(pgd_attack, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T21:36:19.973815Z","iopub.execute_input":"2025-07-10T21:36:19.974090Z"}},"outputs":[{"name":"stderr","text":"Adversarial Test (PGD):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/79 [07:05<07:39, 11.22s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\n\n# ---------------- CW Attack Setup ----------------\ncw_c = 1e-3\ncw_kappa = 0\ncw_steps = 100\ncw_lr = 0.01\n\ncw_attack = torchattacks.CW(model, c=cw_c, kappa=cw_kappa, steps=cw_steps, lr=cw_lr)\n\n# ---------------- CW Adversarial Accuracy Function ----------------\ndef adversarial_test_cw(attack, loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    for inputs, labels in tqdm(loader, desc=f\"Adversarial Test (CW)\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    acc = correct / total\n    print(f\"ðŸ“Š CW Accuracy (c={cw_c}, kappa={cw_kappa}): {acc:.4f}\")\n    return acc\n\n# ---------------- Run CW Evaluation ----------------\ncw_acc = adversarial_test_cw(cw_attack, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}